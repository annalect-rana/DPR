% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/red_function_hive2.r
\name{gold_red_function}
\alias{gold_red_function}
\title{DEPRECATED - PLEASE USE THE GOLD_FUNCTION INSTEAD}
\usage{
gold_red_function(username, pw, dbname = "annalectuk",
  dbHost = "54.77.118.78", KeyID, SecretAccessKey, clust_size, DPID,
  conv_type = "C", data_source = "DC", chan_merge = "S",
  join_type = "Left", agency, networkId, advertiserIds, campaignIds,
  activity_sub_type, activity_type = NULL, eventid.ign = NULL, startDate,
  endDate, startPre, endPre, NVprior = 90, sample = 20, file_save_location,
  hierarchy_location, ppc_hierarchy_location = NULL, ppc_match_col = NULL,
  group = F)
}
\arguments{
\item{username}{The username for redshift}

\item{pw}{The password for that username}

\item{dbname}{Database name, defaults to "annalectuk"}

\item{dbHost}{Database host, defaults to "54.77.118.78"}

\item{KeyID}{AWS Access Key ID}

\item{SecretAccessKey}{AWS Secret Access Key}

\item{clust_size}{AWS size of cluster}

\item{DPID}{Unique identifier for this DP run. Must not contain spaces or any special characters}

\item{conv_type}{The conversion type of run you want to do. "C" for standard conversion, "NV" for new visitors, and "NVC" for new visitors conversions. When using "NV" and "NVC" don't forget to specify your prior period with the NVPrior option. Inputing a number between 0 and 1 will perform standard conversion but will sample the number of user_ids to the ratio you specify. i.e. 0.25 would give you a quarter of all the user_ids.}

\item{data_source}{The data source. "DC" for Double Click}

\item{chan_merge}{The channel merge method. "S" for a standard join to the Hierarchy File on page_id only.  "K" is for Keyword matching, and "KP" for keyword and page_id matching. If you select these you need to include ppc_hierarchy_location, and ppc_match_col}

\item{join_type}{The join type between the clicks nad impressions to the hierarchy. "left" for a left join. Any pageIDs not in the hierarchy file will be filled in with "Other". "inner" for an inner join. Only channels in the hierarchy file will be included in the analysis.}

\item{agency}{What agency are you? eg "m2m", "omd", "mg", "phd". If you are using networkId 33505 (Liberty Global) then the Agency should be the country eg "uk", "be". You will also need to ensure you are accessing the correct database eg dbname="lgiemea"}

\item{networkId}{The network ID for the Double Click data. If you are using networkId 33505 (Liberty Global) then the Agency should be the country eg "uk", "be". You will also need to ensure you are accessing the correct database eg dbname="lgiemea"}

\item{advertiserIds}{A character vector of advertiser ids to select}

\item{campaignIds}{A character vector of campaign ids to select}

\item{activity_sub_type}{what activity sub type are we interested in?}

\item{startDate}{the start date of the DP in "YYYY-MM-DD" format}

\item{endDate}{the end date of the DP in "YYYY-MM-DD" format}

\item{startPre}{the start date of the warmup period for the DP in "YYYY-MM-DD" format}

\item{endPre}{the end date of the warmup period for the DP in "YYYY-MM-DD" format}

\item{NVprior}{when running for New Vistors the length of the prior period in which "new" visitors must not have been seen in}

\item{sample}{The sample sizes to feed into the model. Specify a multiple of converters you want from the non_converters i.e 20. Will give you 20 non-converters for every converter. Or specify a maximum limit for converters and non-converters i.e. c(50000, 500000) This would ensure you get a maximum of 50K converters and 500K non-converters. However if there are fewer than that available, it will just take as many as are available.}

\item{file_save_location}{This is where you would like the intermediate files (between red and blue processes) to be saved.}

\item{hierarchy_location}{Where the hierarchy is saved. The hierachy file must contain 4 columns in this order page_id, buy_id, channel, sub_channel. It should also contain headers in the first row only. sub_channels must be unique. i.e. you can't have the same sub_channel under two different channels. channel and sub_channel names must not begin with numeric characters, and must only contain alphanumerics or underscores '_'. For example "Display Channel" would be "Display_Channel"}

\item{ppc_hierarchy_location}{The location of your keyword matching file. For keyword matching it should be a csv containing following three columns in this order: ppc_match_col, channel, sub_channel. For keyword and page_id matching it should be a csv containing following four columns in this order: page_id, ppc_match_col, channel, sub_channel. In both cases it should also contain headers in the first row only. sub_channels must be unique. i.e. you can't have the same sub_channel under two different channels. channel and sub_channel names must not begin with numeric characters, and must only contain alphanumerics or underscores '_'. For example "Display Channel" would be "Display_Channel"}

\item{ppc_match_col}{The name of the column in the dartsearch table you wish you perform keyword matching with. Either ds_campaign_name or kw_ad_group_name}

\item{group}{If you are part of the central team and don't have access to agency s3 buckets set this to true to run in the group area. By default FALSE}
}
\value{
Summary statistics of the run process. The data is saved down in the file_save_location ready for use with the blue_function, rather than sent to the console.
}
\description{
DEPRECATED - PLEASE USE THE GOLD_FUNCTION INSTEAD
}
\examples{

#gold_red_function(username="xxxxx", pw="xxxxx", dbname="annalectuk", dbHost="54.77.118.78",
#                  KeyID="xxxxx", SecretAccessKey="xxxxx", clust_size=20,
#                  DPID="test_run", agency="omd", networkId="530",
#                  conv_type = "C", data_source = "DC", chan_merge = "L", 
#                  advertiserIds=c(856279,1040292), 
#                  campaignIds=c(8608700,8685166,8275648,8704058,8581290,6158304,7945110,8722740,7888562,8373606),
#                  activity_sub_type=c("2014_000","2014_001"), 
#                  startDate="2015-06-01", endDate="2015-06-30", startPre="2015-05-20", endPre="2015-05-31", 
#                  sample = 20,
#                  file_save_location="P:/DPR/test_run/output", hierarchy_location="P:/DPR/test_run/Hierarchy/Hierarchy_file.csv")
#                  
#
}
\references{
\url{https://bitbucket.org/omguk-annalect/dpr/wiki/Home}
}
\author{
James Thomson, \email{james.thomson@omnicommediagroup.com}
}
